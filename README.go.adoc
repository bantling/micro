// SPDX-License-Identifier: Apache-2.0
:doctype: article

== Go Port

This file describes the Go port of micro.

=== Source code location

The Go code is stored at the top level project directory. This means the code is stored online at github.com/bantling/micro,
which means import statements in go can import any package as `import github.com/bantling/micro/<package>`.

=== Packages

* constraint
** defines generic type constraints, some are similar to golang.org/x/exp/constraints
* conv
** converts between numeric types, returning an error if any loss of precision would occur
* encoding/json
** Value type that describes any kind of JSON value
** convert between go types to Value and vice-versa (eg, map[string]any -> Value of type Object -> map[string]any)
** default numeric type is NumberString, but custom conversion functions can be used
** search a Value with a string path like .addresses[3].city
** parse package has streaming parser that can provide individual elements of top level array as they are read in, so
   that a large number of elements can be processed without having to read entire input.
** write package writes a json.Value to an micro/io/Writer[rune], which in turn writes to an io.Writer
* event
** A simple system for sending events and getting results back
** Same generic type is used for input and output
** Receivers are partitioned by an ordered id type, where a given id value is associated with any number of receivers
** When an event is sent, it is sent to all receivers of the lowest id value, then all receivers of the next lowest id value, etc.
** This for flow like the following:
*** lowest id is unmarshalling a JSON Value
*** next id is converting JSON to a struct
*** next id is any number of validators
*** next id is persisting to database
*** at any time, new validators could be added, steps can be reordered just by registering with different ids
*** changes could be made on the fly, at compile time, or both
* funcs
** slices:
*** flatten multiple dimensions into one
*** access elements safely
*** remove elements
*** reverse elements
*** sort elements
** maps:
*** access keys safely
*** sort key/value pairs
** filters - func(T) bool:
*** compose with and, or, not
*** generate filters for comparisons (<, <=, ==, >=, >)
*** generate filters for is negative, is non-negative, is positive, is nil, is non nil
** compose any number of funcs that accept and receive same type
** compose 2 to 10 funcs that accept and return different types
** ternary - take a (bool, true value, false value) or (bool, true supplier, false supplier), and return true or false value
** min/max
** nil handling
** error handling
** supplier generators
** generate a func that ignores result of another func
** TryTo is a replacement for awkward idiomatic go code that acts like a Java try/catch/finally block:
   Accepts a func for a try block, a func for a catch block (only invoked if try block panics), and any number of
   closer funcs that close resources regardless of whether the try func panics.
* io
** ErrorReader and ErrorWriter returns a specified error after reading or writing a specified set of bytes, mostly useful
   for unit tests.
** writer package is reverse of Iter, writes values to a destination rather than reading. Mostly concerned with writing to IO.
* iter
** defines Iter type that can iterate anything
** based on iterating funcs, a func of no args that returns (value, bool), where the value is only relevant if the bool
   is true
** A number of constructors are provided for hard-coded values, slices, maps, io.Reader, concat multiple iters
** Next method returns (T, error)
** Unread method builds a buffer that is read in reverse order (eg Unread(1) followed by Unread(2) provides values 2, 1)
** Maybe func accepts an Iter and returns a Result, which provides either a value or an error
** SetError func accepts an Iter and an error, and returns a new Iter that returns the given error after exhausting the Iter.
   Mostly useful for unit tests.
* math
** absolute value calculation that returns an error for lowest negative value of integers
   (eg for int8, abs(-128) = -128 because highest positive value is 127)
** add/subtract/multiply integers and return an error if over/underflow occurs
** integer division that rounds quotient up when remainder >= half way point
** generate a mask of n consecutive 1 bits that are left or right aligned
** min and mask functions for all numeric types
** decimal type
*** accurate decimal addition, subtraction, and multiplication
*** division by integers only
** Range can hold a range of values between a minimum and maximum, where minimum and maximum values themselves may or
   may not be allowed. Attempting to set the value outside the range returns an error and does not change the value.
* reflect
** utilities to make reflection usage easier
** DerefType derefs a Type until it is not a pointer
** DerefTypeMaxOnePtr derefs a Type until it is zero or one pointers (eg, two or more pointers get derefd to one pointer)
** DerefValue derefs a Value until it is not a pointer. If any pointer is nil, an invalid Value is returned.
** DerefValueMaxOnePtr derefs a Value until it is zero or one pointers (eg, two or more pointers get derefd to one pointer)
   If any pointer except the last one is nil, an invalid Value is returned.
** FieldsByName collects the fields of a struct into a map
** IsBigPtr returns true if the given type is a *big.Int, *big.Float, or *big.Rat, and false otherwise
** IsNillable returns true if a Value or Type represents a type that can be assigned nil
** IsPrimitive returns true if a Value or Type represents a primitive value
** ResolveValueType resolves the type of a Value so it is not interface{} (eg, an interface{} that is really an int resolves to int).
   If the Value is already not interface{}, it is returned as is.
** ToBaseType converts zero or one pointers to a primitive subtype to the underlying type (eg rune -> int32, or *rune to *int32)
** ValueMaxOnePtrType returns the underlying Type of zero or one pointers to a Value.
   If the Value given has multiple pointers, the Value is not a valid parameter value, and the result is nil.
* rest
** Simple ServeMux very similar to net/http/ServeMux
*** Considers verb and url to determine which Handler to execute
*** Handle method accepts a string regex (compiled with regexp package) which can have groups for path parts
*** Handler method accepts a slice of path parts for the values of the above groups provided by the client
*** sets sttaus and message to 404 if url not matched, 405 if url matches, but not the method
*** When a handler is executed, the handler sets the status and message
* stream
** Provides streaming functionality (similar to that of Java 8 streams).
** Some functions take params and return a func of Iter[T] -> Iter[U]
** Remaining functions are a func of Iter[T] -> Iter[U]
** All functions are a transform
** Funcs that result in zero or one elements return an Iter instead of a Result, to allow continued usage of other
   funcs that accept and return iters.
* tuple
** Tuples of 2, 3, or 4 elements of one generic type or separate generic types
* union
** Unions of 2, 3 or 4 elements of separate generic types
** Result is union of one generic type and an error

=== Dependency Graph

A dependency graph can be generated anytime by running `make depgraph.png`.

=== Makefile

[cols="1,1,1"]
|===
|Target
|Purpose
|Options

|all (default)
|Runs most targets
|

|more
|Runs all and paginates the results with more
|

|docker
|Builds in a docker container such that every build has to download dependencies and build from scratch
|

|docker-check-image
|Pulls docker go image if it has not already been pulled
|

|docker-cache
|Builds in a docker container with caching for dependencies and compiling across builds
|

|podman
|Builds in a podman container such that every build has to download dependencies and build from scratch
|

|podman-check-image
|Pulls podman go image if it has not already been pulled
|

|podman-cache
|Builds in a podman container with caching for dependencies and compiling across builds
|

|tidy
|Runs `go mod tidy`, and cleanup tasks for docker-cache or podman-cache
|

|compile
|Runs `go build ./...`, and cleanup tasks for docker-cache or podman-cache
|

|lint
|Runs `go vet ./...`
|

|format
|Runs `gofmt -s -w` in every go package dir to format source code
|

|test
|Tests go code in every go package dir
|`-count=num` to run tests N times, `pkg=./package_name` to test only one package, `run=test_name` to run matching tests

|coverage
|Runs display code coverage in default browser
|

|spdx
|Ensures every go source file contains an spdx license line
|

|check-doc-go
|Ensures every go package contains a doc.go file
|

|have-dot
|Ensures GraphViz dot program exists
|

|.dephraph.dot
|Generates graph of packages with hard-coded node colouring
|

|.depgraph.png
|Png image generated by dot program using .depgraph.dot as source
|

|.deplegend.dot
|Generates a legend graph indicating what the node colours represent
|

|.deplegend.png
|Png image generated by dot program using .deplegend.dot as source
|

|have-gm
|Ensures GraphicsMagick gm program exists
|

|depgraph.png
|Combined dependency graph and legend image generated by gm program using .depgraph.png and .deplegend.png as source
|

|have-asciidoc
|Ensures asciidoc program exists
|

|.readme.html
|Generates an HTML version of top level README.adoc using asciidoc, output should be the same as GitHub or GitLab
|

|.readme.go.html
|Generates an HTML version of this README using asciidoc, output should be the same as GitHub or GitLab
|

|push
|git add -A; git commit -m Changes; git push
|

|vars
|Display values of make vars defined in this Makefile
|

|clean
|Removes docker and podman caches from host, along with dependency graph and readme html files
|
|===

=== TODO

* For all TryTo usage in unit tests that are supposed to fail, ensure that a bool is declared, set to true by the panicFn, and tested as true after TryTo call
* I don't think decimal rounding is correct in AdjustDecimalScale
** Appears to just examine most significant decimal place for >= 5
** Instead, round starting at last decimal place
** If resulting most significant decimal place >= 5, then round integer portion
* add a reflect func to take a map[string]any and populate a struct with it
** consider pointers, Maybe, and JSON
** use conv.To to convert individual map key values into struct fields
** if a struct field is a JSON Value, use conv.To to convert map key value into JSON
** maybe no special handling of JSON is required, maybe instead try using LookupConversion from map key value to field,
   and if no such conversion exists and map key value is a submap and field is a sub struct, then recurse into it
* rename union.Maybe.SetOrError to SetOrDie since it panics
* json Value should just be its own union, not based on union.Four
* add C64 style BASIC
** Named funcs that can accept params and/or return value(s)
** globals can be constant or variable
** Extensible - parser can accept (command, func(string, executionContext) error)
*** command is a string name of a command that is not builtin, and not registered already
*** func accepts all chars after the command up to the end of the command, and parses it
*** executionContext allows reading/writing all current vars (global and local), defining and calling any functions
*** if a func returns an error, execution stops
*** globals, structs, and funcs arranged in packages
*** all code parsed before execution begins
*** oop syntax, where depth of subclass trees is known in advance, due to parsing of all code, so no vtable, just a map[name] func
*** possible to write a script with no functions, declare variables with a syntax that indicates they are inputs, and end
    with a return statement (to provide one or more results), or no return (modify inputs) or both (modify inputs and return)
* reflect complete struct recursion testing
* conv
** add handling for json.Value, where json.NullValue is equivalent to a nil pointer or empty Maybe
** since encoding/json refers to conv, conv cannot refer to encoding/json
** option 1: move encoding/json/init.go to encoding/json/conv/init.go - shd be ok, seems to only use exported functions
** option 2: extend conv.LookupConversion to have WrapperInfo
*** Indicates what type a wrapper type currently contains
*** Indicates what types the wrapper can accept
*** Indicates if wrapped value is currently nil
*** Allows setting the wrapped value to any type it says it can accept
*** Have maybe implement WrapperInfo and replace current conv Maybe logic with WrapperInfo
*** Have JSON implement WrapperInfo and above change to conv to use WrapperInfo should just work
* Add ability to use star characters (*) in json path expressions in following places, where * = regex .*:
** key name (all or partial) - eg .first* (all keys of current object), .* (all keys)
** array index - eg [*] (all array indexes of current object)
** key name and array indexes - .[]* (all keys/indexes of current object/array and children, recursively)
** returns a []Value instead of a single Value
** examples:
*** .addresses.[*].city: the cities of every address, in order encountered in the array
*** .address*[3].city: the third city of every object key whose name begins with address
*** .addresses.[]*.city: recursively search all sub objects and array indexes of addresses key for objects that have a city
* Finish decimal by adding division by another decimal using BCD and longhand division
* make a Dockerfile that uses https://github.com/GoogleContainerTools/distroless/blob/main/base/README.md
  and uses gcr.io/distroless/static
* modify stream parallel func to have an additional criteria of max threads
** idea is to only create at most max threads even if number of chunks > max threads
** new outer loop that executes existing code loop, until all chunks processed
* add capability in reflect package to populate a struct from a map, or map from a struct
** use conv.To to convert map elements to struct fields, to correctly handle subtypes, pointers, Maybes, etc
** field kind must be bool, ints, floats, complex, array, map, slice, string, or struct/*struct
** fields of sub struct/*struct must be above types
** pointer and Maybe fields can handle null/empty inputs
** support case conversions, with built-in converters for UpperCamel/lowerCamel, Upper_Snake/lower_snake, Upper-Kebab, lower-kebab
** each case conversion is a pair of func(string) string, with each func the converse of the other
* simple ORM
** map tables to structs, using reflect package map struct, translating column name <-> field name using any available case conversion
** query structs, where each field is a func with a spring data like name (no child fields), or field has a struct tag with query
** query structs fields can be select, insert, update, upsert, or delete
* Tasks
** Task[Id comparable, Res any] is a struct{id Id, func(ctx context.Context) (Res, error)}
** Task is constructed from (Id, func(ctx context.Context) (Res, error))
** Task.Perform() (map[Id]union.Result[Res]) calls func passed to constructor
*** If it panics, Task maps id to error Result of fmt.Errorf("Task id %v panicked with %#v", Task.id, recovered value)
*** If it returns an error, Task maps id to Result of returned error
*** Else Task returns nil map
*** A map is used so that Tasks can be composed in various ways, and get results of each Task
** Schedule[Id, Res](Duration | Time, sched, done, errTask Task[Id, Res]) Task[Id, sync.WaitGroup]
*** Returns a Task that executes the given sched Task arg after specified duration / at specified time,
    and then executes the done Task if it completed successfully, errTask if it did not.
*** When executed, the scheduled task is immediately executed in a separate go routine, and the WaitGroup is returned.
*** If Task is a duration, the duration is applied when the task is run, no matter how long of a delay occurs between
    constructing the Task and executing it
*** If Task is at a specified time, it returns immediately if that time has already passed when it is executed
** Join[Id, Res](JoinMode, Task[Id, Res]...) Task[Id, Res]
*** Returns as Task that executes a series of tasks in given JoinMode (STOP_ON_FIRST_ERROR, IGNORE_ERRORS)
*** Task.Perform() maps each Id to a tuple.Result to allow determination of which Tasks succeeded, which failed, and the errors
** RepeatTask(JoinMode, Task[Id, Res], uint count) Task[Id, Res] executes the same Task count times sequentially
*** Perform() maps Id to a Result same as Join
** ParallelTask[Id, Res](ParallelMode, Task[Id, Res]...)
*** Returns a Task that executes a series of tasks in separate in multiple go routines
*** ParallelMode functions same as streaming api
** Can a Task be used as async/await?
** Can a Task be used as a Promise?
* ETL
** Mainly operating on streams, with 3 basic operation types:
*** Combine streams
*** Split streams
*** Generate streams
** Look at steps Pentaho and Talend provide as a rough guide
* Consider porting https://github.com/dnotq/decNumber to Go for arbitrary precision decimal math
